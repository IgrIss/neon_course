{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sentiment Analysis of Movie Reviews\n",
    "\n",
    "\n",
    "In this exercise, we will write a model to analyze movie reviews on IMDB and decide if they are positive or negative reviews.\n",
    "\n",
    "The IMDB dataset consists of 25,000 reviews, each with a binary label (1 = positive, 0 = negative).\n",
    "\n",
    "Here is an example of a POSITIVE review:\n",
    "\n",
    "> \"The pace is steady and constant, the characters full and engaging, the relationships and interactions natural showing that you do not need floods of tears to show emotion, screams to show fear, shouting to show dispute or violence to show anger. Naturally Joyce's short story lends the film a ready made structure as perfect as a polished diamond, but the small changes Huston makes such as the inclusion of the poem fit in neatly. It is truly a masterpiece of tact, subtlety and overwhelming beauty.\"\n",
    "\n",
    "Here is an example of a NEGATIVE review:\n",
    "\n",
    "> \"Beautiful attracts excellent idea, but ruined with a bad selection of the actors. The main character is a loser and his woman friend and his friend upset viewers. Apart from the first episode all the other become more boring and boring. First, it considers it illogical behavior. No one normal would not behave the way the main character behaves. It all represents a typical Halmark way to endear viewers to the reduced amount of intelligence. Does such a scenario, or the casting director and destroy this question is on Halmark producers. Cat is the main character is wonderful. The main character behaves according to his friend selfish.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "1. Setup\n",
    "--------\n",
    "\n",
    "We first generate a compute backend and provide some needed settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from neon.backends import gen_backend\n",
    "\n",
    "be = gen_backend(backend='gpu', batch_size=128, rng_seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We also import all the components we need for this exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from neon.data.text_preprocessing import clean_string\n",
    "from neon.initializers import Uniform, GlorotUniform\n",
    "from neon.layers import LSTM, Affine, Dropout, LookupTable, RecurrentSum, Recurrent\n",
    "from neon.transforms import Logistic, Tanh, Softmax\n",
    "from neon.models import Model\n",
    "from neon.optimizers import Adagrad, GradientDescentMomentum, Schedule\n",
    "from neon.transforms import CrossEntropyMulti\n",
    "from neon.layers import GeneralizedCost\n",
    "from neon.callbacks import Callbacks\n",
    "from neon.transforms.cost import Accuracy\n",
    "from viz_callback import CostVisCallback\n",
    "from imdb import IMDB\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "2. Dataset\n",
    "----------\n",
    "\n",
    "We have to preprocess the dataset to convert the words into numbers. We take our vocabularly of words, and assign a number to each word. For example, a sentence such as:\n",
    "\n",
    "> \"Hello world, my name is Intel and my location is Santa Clara\"\n",
    "\n",
    "Will be converted to list of 6 numbers:\n",
    "\n",
    "> [24, 784, 4, 98, 22, 143, 15, 4, 314, 22, 488, 2894] \n",
    "\n",
    "We already done this for you, and is loaded in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imdb = IMDB(be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "3. Build the Model\n",
    "-----------------\n",
    "\n",
    "We initialize the parameters with uniform random numbers ranging from `-1/128` to `1/128`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init_uniform = Uniform(-0.1/128, 0.1/128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The network consists of list of the following layers:\n",
    "\n",
    "1. `LookupTable` transforms each word into a vector of numbers. \n",
    "2. `LSTM` is a recurrent layer with “long short-term memory” units. LSTM networks are good at learning temporal dependencies in the data.\n",
    "3. `RecurrentSum` sums the output from the LSTM layer across the different time steps.\n",
    "4. `Dropout` randomly silences a subset of the units during training.\n",
    "5. `Affine` is a layer with two outputs, for the two target classes.\n",
    "\n",
    "Below we first create a list of layers, then create the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(LookupTable(vocab_size=20000, embedding_dim=128, init=init_uniform))\n",
    "layers.append(LSTM(output_size=64, init=GlorotUniform(), activation=Tanh(),\n",
    "              gate_activation=Logistic(), reset_cells=True))\n",
    "layers.append(RecurrentSum())\n",
    "layers.append(Dropout(0.5))\n",
    "layers.append(Affine(nout=2, init=GlorotUniform(), bias=GlorotUniform(), activation=Softmax()))\n",
    "\n",
    "# create model object\n",
    "model = Model(layers=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "4. Select the Algorithm\n",
    "------------\n",
    "For training, we set up the cost function, which we want to minimize. We also select an optimization algorithm with a particular learning rate `0.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define cost\n",
    "cost = GeneralizedCost(costfunc=CrossEntropyMulti(usebits=True))\n",
    "\n",
    "# use Adagrad algorithm with a learning rate of 0.01\n",
    "optimizer = Adagrad(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Callbacks allow the model to report its progress during the course of training. Here we tell neon to plot a graph with the cost over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "callbacks = Callbacks(model, eval_set=imdb.valid_set)\n",
    "callbacks.add_callback(CostVisCallback(nepochs=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train model\n",
    "-----------\n",
    "\n",
    "Now are ready to train the model. Recall what happens during the training process:\n",
    "\n",
    "<img src=\"train_schematic.png\" width=700px>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To train the model, we call the `fit()` function and pass in the training set. Here we train for 2 epochs, meaning two rounds through the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(imdb.train_set, optimizer=optimizer, num_epochs=2,\n",
    "          cost=cost, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Accuracy\n",
    "--------\n",
    "\n",
    "We can then measure the model's accuracy on the validation data -- data that the model was not trained on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Test  Accuracy - {}\".format(100 * model.eval(imdb.valid_set, metric=Accuracy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Inference\n",
    "--------\n",
    "\n",
    "Now let's do something fun with the trained model! We create a UI below where you can type in your movie review (or any other text) and have it classified into positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from imdb import preprocess\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from imdb import text_window\n",
    "\n",
    "def inference(x):\n",
    "    input_data = be.zeros((128, be.bsz), dtype=np.int32)\n",
    "    preprocess(x, input_data)\n",
    "    result = model.fprop(input_data, inference=True)\n",
    "    print(\"Sentiment: {:.1f}% Positive\".format(100*result.get()[1][0]))\n",
    "    \n",
    "z = interact(inference, x=text_window())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note: In some browsers, the above text window may not show up. In that case,run the below code to do inference. Feel free to edit the text inside the quotes and re-run the code to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inference(\"This movie was terrible!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
